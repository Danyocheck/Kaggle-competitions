{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! kaggle competitions download -c playground-series-s4e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! unzip playground-series-s4e6.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('train.csv')\n",
    "y = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up the visualizations\n",
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "# Visualize the distribution of the target variable\n",
    "plt.subplot(3, 2, 1)\n",
    "sns.countplot(data=X, x='Target')\n",
    "plt.title('Distribution of Target Variable')\n",
    "\n",
    "# Visualize the distribution of 'Age at enrollment'\n",
    "plt.subplot(3, 2, 2)\n",
    "sns.histplot(data=X, x='Age at enrollment', kde=True, bins=30)\n",
    "plt.title('Distribution of Age at Enrollment')\n",
    "\n",
    "# Visualize the distribution of 'Admission grade'\n",
    "plt.subplot(3, 2, 3)\n",
    "sns.histplot(data=X, x='Admission grade', kde=True, bins=30)\n",
    "plt.title('Distribution of Admission Grade')\n",
    "\n",
    "# Visualize the distribution of 'Gender'\n",
    "plt.subplot(3, 2, 4)\n",
    "sns.countplot(data=X, x='Gender')\n",
    "plt.title('Distribution of Gender')\n",
    "\n",
    "# Visualize the distribution of 'Scholarship holder'\n",
    "plt.subplot(3, 2, 5)\n",
    "sns.countplot(data=X, x='Scholarship holder')\n",
    "plt.title('Distribution of Scholarship Holders')\n",
    "\n",
    "# Visualize the relationship between 'Admission grade' and 'Target'\n",
    "plt.subplot(3, 2, 6)\n",
    "sns.boxplot(data=X, x='Target', y='Admission grade')\n",
    "plt.title('Admission Grade vs. Target')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X.columns[X.nunique() < 40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for class imbalance in the targelt.xlabel('Target')\n",
    "# plt.ylabel('Count')\n",
    "# plt.show(\n",
    "\n",
    "# Visualize the relationships between features and the target variable\n",
    "# Selecting a few features for visualization\n",
    "\n",
    "\n",
    "features_to_visualize = X.columns[X.nunique() < 40]# Plotting the distributions of these features with respect to the target variable\n",
    "fig, axs = plt.subplots(nrows=10, ncols=3, figsize=(18, 36))\n",
    "for ax, feature in zip(axs.flatten(), features_to_visualize):\n",
    "    sns.countplot(data=X, x=feature, hue='Target', palette='viridis', ax=ax)\n",
    "    ax.set_title(f'{feature} Distribution by Target')\n",
    "    ax.set_xlabel(feature)\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.legend(title='Target')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    dict = {\n",
    "        'Enrolled': 1,\n",
    "        'Dropout': 0,\n",
    "        'Graduate': 2,\n",
    "    }\n",
    "    data['Target'] = data['Target'].map(dict)\n",
    "    return data\n",
    "X = preprocess(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_features(data):\n",
    "    data['Total_Curricular_units_enrolled'] = data['Curricular units 1st sem (enrolled)'] + data['Curricular units 2nd sem (enrolled)']\n",
    "    data['Total_Curricular_units_approved'] = data['Curricular units 1st sem (approved)'] + data['Curricular units 2nd sem (approved)']\n",
    "    data['Total_Curricular_units_grade'] = data['Curricular units 1st sem (grade)'] + data['Curricular units 2nd sem (grade)']\n",
    "    data['Average_Curricular_units_grade'] = data['Total_Curricular_units_grade'] / (data['Total_Curricular_units_enrolled'] + 1e-9)\n",
    "    data['Performance_ratio'] = data['Total_Curricular_units_approved'] / (data['Total_Curricular_units_enrolled'] + 1e-9)\n",
    "    data['tuition_debtor'] = ((data['Tuition fees up to date'] == 0) & (data['Debtor'] == 1)).astype(int)\n",
    "\n",
    "    data['Academic_growth'] = data['Curricular units 2nd sem (grade)'] - data['Curricular units 1st sem (grade)']\n",
    "    data['Stability_index'] = abs(data['Curricular units 1st sem (enrolled)'] - data['Curricular units 2nd sem (enrolled)']) + abs(data['Curricular units 1st sem (approved)'] - data['Curricular units 2nd sem (approved)'])\n",
    "    data['Financial_strain'] = ((data['Scholarship holder'] == 0) & (data['tuition_debtor'] == 1)).astype(int)\n",
    "\n",
    "    return data\n",
    "\n",
    "X = new_features(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoost, Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y = X['Target']\n",
    "X.drop(columns=['id', 'Target'], inplace=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# train_data = Pool(data=X_train, label=y_train, cat_features=['tuition_debtor', 'Debtor', 'Tuition fees up to date'])\n",
    "# test_data = Pool(data=X_test, cat_features=['tuition_debtor', 'Debtor', 'Tuition fees up to date'])\n",
    "params = {'iterations': 1000,  \"learning_rate\": 0.1, 'depth': 10, 'loss_function': 'MultiClass',\n",
    "                'cat_features': ['Marital status', 'Application mode', 'Nacionality', 'Gender', \n",
    "                                'Scholarship holder', 'Debtor', 'Tuition fees up to date', \n",
    "                                'Previous qualification', \"Mother's qualification\", \"Father's qualification\",\n",
    "                                \"Mother's occupation\", \"Father's occupation\", 'Daytime/evening attendance', 'tuition_debtor'\n",
    "                                ],\n",
    "                'verbose': 0, 'task_type': 'GPU', 'devices': '0-7'}\n",
    "model = CatBoost(params=params)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test, prediction_type='Class')\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_features = [\n",
    "#     'Marital status', 'Application mode', 'Nacionality', 'Gender', \n",
    "#     'Scholarship holder', 'Debtor', 'Tuition fees up to date', \n",
    "#     'Previous qualification', \"Mother's qualification\", \"Father's qualification\",\n",
    "#     \"Mother's occupation\", \"Father's occupation\", 'Daytime/evening attendance', 'tuition_debtor'\n",
    "# ]\n",
    "feature_importances = model.get_feature_importance(Pool(X_train, y_train), type=\"FeatureImportance\")\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Create a dataframe for plotting\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "\n",
    "# Sort the dataframe by importance\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot the feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "lgb_tr = lgb.Dataset(X_train, y_train)\n",
    "params = {'objective': 'multiclass', 'num_class': '3',\n",
    "          'metric': 'multi_logloss', 'eta': 0.01, 'verbosity': -1,\n",
    "          'device': 'gpu', 'gpu_platform_id': 0, 'gpu_device_id': 0,\n",
    "          'num_gpu': '7'}\n",
    "\n",
    "model = lgb.train(\n",
    "    params, lgb_tr, num_boost_round=1000,\n",
    "    valid_sets=[lgb_tr], valid_names=['train'], callbacks=[lgb.log_evaluation(period=50)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "pred = np.argmax(pred, axis=1)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y = X['Target']\n",
    "X.drop(columns=['id', 'Target'], inplace=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Initialize the CatBoost model\n",
    "catboost_model = CatBoostClassifier(iterations=1000, learning_rate=0.1, depth=10,\n",
    "                                    verbose=0, task_type='GPU', \n",
    "                                    devices='0-7'\n",
    "                                    )\n",
    "\n",
    "# Train the model on the training set\n",
    "catboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Plot Feature Importance\n",
    "feature_importances = catboost_model.get_feature_importance(Pool(X_train, y_train), type=\"FeatureImportance\")\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Create a dataframe for plotting\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "\n",
    "# Sort the dataframe by importance\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot the feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def objective(trial):\n",
    "    model = CatBoostClassifier(\n",
    "        cat_features=['tuition_debtor', 'Debtor', 'Tuition fees up to date', ],\n",
    "        iterations=trial.suggest_int(\"iterations\", 500, 2000),\n",
    "        learning_rate=trial.suggest_float(\"learning_rate\", 1e-3, 1e-1, log=True),\n",
    "        depth=trial.suggest_int(\"depth\", 2, 6),\n",
    "        l2_leaf_reg=trial.suggest_float(\"l2_leaf_reg\", 1e-8, 100.0, log=True),\n",
    "        bootstrap_type=trial.suggest_categorical(\"bootstrap_type\", [\"Bayesian\"]),\n",
    "        random_strength=trial.suggest_float(\"random_strength\", 1e-8, 10.0, log=True),\n",
    "        bagging_temperature=trial.suggest_float(\"bagging_temperature\", 0.0, 10.0),\n",
    "        od_type=trial.suggest_categorical(\"od_type\", [\"IncToDec\", \"Iter\"]),\n",
    "        od_wait=trial.suggest_int(\"od_wait\", 10, 50),\n",
    "        verbose=False,\n",
    "        task_type='CPU',\n",
    "        loss_function='MultiClass'\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "bohb_sampler = optuna.samplers.TPESampler(n_startup_trials=30, n_ei_candidates=13, multivariate=True)\n",
    "study = optuna.create_study(sampler=bohb_sampler, direction='maximize')\n",
    "study.optimize(objective, n_trials=300, show_progress_bar=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.visualization import plot_slice\n",
    "\n",
    "plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from catboost import CatBoostClassifier\n",
    "# import numpy as np\n",
    "# cat_features = ['Marital status', 'Application mode', 'Daytime/evening attendance', \n",
    "#                 'Nacionality', \"Mother's qualification\", \"Father's qualification\", \n",
    "#                 \"Mother's occupation\", \"Father's occupation\", 'Course']\n",
    "\n",
    "# # Initialize the CatBoost model\n",
    "# classifier = CatBoostClassifier(\n",
    "#     n_estimators=1000,\n",
    "#     depth=3,  # Adjusted depth for better learning capacity\n",
    "#     loss_function='MultiClass',\n",
    "#     verbose=False,\n",
    "#     learning_rate=0.1,\n",
    "#     cat_features=cat_features,\n",
    "#     eval_metric='Accuracy',\n",
    "#     task_type='GPU',\n",
    "#     devices='0-7'\n",
    "# )\n",
    "\n",
    "# # Define the parameter grid\n",
    "# param_grid = {\n",
    "#     'l2_leaf_reg': np.linspace(0, 5, 10)\n",
    "# }\n",
    "\n",
    "# # Perform grid search\n",
    "# classifier.grid_search(param_grid, X_train, y_train, cv=5, plot=True, refit=True, verbose=False)\n",
    "\n",
    "# # Evaluate the model on the test set\n",
    "# y_pred = classifier.predict(X_test)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(f\"Test Set Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = pd.read_csv('train.csv')\n",
    "# X_test = pd.read_csv('test.csv')\n",
    "\n",
    "# X = preprocess(X)\n",
    "# X = new_features(X)\n",
    "\n",
    "# X_test = new_features(X_test)\n",
    "\n",
    "# y = X['Target']\n",
    "# X_train = X.drop(columns='Target')\n",
    "\n",
    "# classifier = CatBoostClassifier(\n",
    "#     n_estimators=1000,\n",
    "#     depth=3,  # Adjusted depth for better learning capacity\n",
    "#     loss_function='MultiClass',\n",
    "#     l2_leaf_reg=0.5555555,\n",
    "#     verbose=False,\n",
    "#     learning_rate=0.1,\n",
    "#     cat_features=cat_features,\n",
    "#     eval_metric='Accuracy',\n",
    "#     task_type='GPU',\n",
    "#     devices='0-7'\n",
    "# )\n",
    "\n",
    "# classifier.fit(X_train, y)\n",
    "# pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dict = {\n",
    "        1: 'Enrolled',\n",
    "        0: 'Dropout',\n",
    "        2: 'Graduate',\n",
    "    }\n",
    "reversed = np.vectorize(target_dict.get)\n",
    "y_pred = reversed(pred)\n",
    "y_pred = y_pred.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['Target'] = y_pred\n",
    "X_test[['id', 'Target']].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! kaggle competitions submit -c playground-series-s4e6 -f submission.csv -m \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
